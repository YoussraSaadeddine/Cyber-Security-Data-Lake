{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Anomaly detection V.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b36b986ad36c4763a586d9e62f0e2b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_397bc2b375574a18844a61d0645f318d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2d1c9fa6a2a47c2a6f27c8a1f958ca9",
              "IPY_MODEL_c3632d1eeb344e02b70d71aa7ba338c4"
            ]
          }
        },
        "397bc2b375574a18844a61d0645f318d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2d1c9fa6a2a47c2a6f27c8a1f958ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ef91b8cf88f46e4a0d6d5bf471e8afc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fc25e699d0c4d988a6a23f90796b52e"
          }
        },
        "c3632d1eeb344e02b70d71aa7ba338c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9551f66456924532955b0806bd619245",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 134kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f196c84166d43259826244dbfd13a0f"
          }
        },
        "0ef91b8cf88f46e4a0d6d5bf471e8afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fc25e699d0c4d988a6a23f90796b52e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9551f66456924532955b0806bd619245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f196c84166d43259826244dbfd13a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ef29c8a924046e085f59d6ec2a6db64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b0d5591b9cd543bba4555266e9eb5f27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a06d4d09b544ec8948082a0d6116c55",
              "IPY_MODEL_5dd116408a5442728c10c0da5e7eac58"
            ]
          }
        },
        "b0d5591b9cd543bba4555266e9eb5f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a06d4d09b544ec8948082a0d6116c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c254936732b42c4b2159be5496fadd2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ad456ac73bc479f9fd4fec3ff0aef94"
          }
        },
        "5dd116408a5442728c10c0da5e7eac58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6b668e3fd3f44f593104159687fa39c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:58&lt;00:00, 7.92kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4d1016e29f042e5889154e7063d93f9"
          }
        },
        "2c254936732b42c4b2159be5496fadd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ad456ac73bc479f9fd4fec3ff0aef94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6b668e3fd3f44f593104159687fa39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4d1016e29f042e5889154e7063d93f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e06978ad029c4affb3af3b5ca277fec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6618a4742da14352a955462205b99f3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f5d50a521a841c89c8187ba717ab60e",
              "IPY_MODEL_4857291f842f45a8b6d6b69e50fe372a"
            ]
          }
        },
        "6618a4742da14352a955462205b99f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f5d50a521a841c89c8187ba717ab60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad1d8f7875cf41279a68c420da1520c8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_424f2c239db04d3283c5dff1df986413"
          }
        },
        "4857291f842f45a8b6d6b69e50fe372a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_effbc0f2fd6644278e58bfab8b01bba1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:55&lt;00:00, 1.99s/B]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_978abe723fe045678fa4863de034a856"
          }
        },
        "ad1d8f7875cf41279a68c420da1520c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "424f2c239db04d3283c5dff1df986413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "effbc0f2fd6644278e58bfab8b01bba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "978abe723fe045678fa4863de034a856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59d30097483c4e3a8d8ae2121c5dc53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc94a6f3a8e14f919a4a6e3de1db5f15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83e4c01facda4f4982586b89890dc7e2",
              "IPY_MODEL_fac50e5d0acd46fdaaca9694f5095aba"
            ]
          }
        },
        "bc94a6f3a8e14f919a4a6e3de1db5f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83e4c01facda4f4982586b89890dc7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34e79c2ee5e942b083bb67e34b7c0458",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad0f5ccf532a42628080c56f53bdd3f8"
          }
        },
        "fac50e5d0acd46fdaaca9694f5095aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bffd8d85d39481bb28ecd22965d025b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [20:29&lt;00:00, 2.16s/B]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1542e7cfd34041ecbe5c329eb74abcd0"
          }
        },
        "34e79c2ee5e942b083bb67e34b7c0458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad0f5ccf532a42628080c56f53bdd3f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bffd8d85d39481bb28ecd22965d025b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1542e7cfd34041ecbe5c329eb74abcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84d0a2b23b664090b6d8892ceba625bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9c9c8e7a73748d593f7e6a3e8892bb7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8f9f9478b224991aed6535280ce8836",
              "IPY_MODEL_7e3083bb14ee49b5a8c1c3f7636e62ac"
            ]
          }
        },
        "c9c9c8e7a73748d593f7e6a3e8892bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8f9f9478b224991aed6535280ce8836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab17dec6b0cb4d7aa9ae4db026ced78a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9d229bd9dd84716b171f06b363b574d"
          }
        },
        "7e3083bb14ee49b5a8c1c3f7636e62ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f653c1eac66e4e7ca60b0d5c45a2b681",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:13&lt;00:00, 31.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6612473ac06c46acab270fb56438d7e3"
          }
        },
        "ab17dec6b0cb4d7aa9ae4db026ced78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9d229bd9dd84716b171f06b363b574d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f653c1eac66e4e7ca60b0d5c45a2b681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6612473ac06c46acab270fb56438d7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDK7UTBgkrK8"
      },
      "source": [
        "##I - Introduction\n",
        "\n",
        "#####2018 a Ã©tÃ© une annÃ©e dÃ©cisive dans le NLP. L'apprentissage par transfert, en particulier des modÃ¨les tels que ELMO d'Allen AI, Open-GPT d'OpenAI et BERT de Google, a fourni au reste de la communautÃ© NLP des modÃ¨les prÃ©-entraÃ®nÃ©s qui pourraient facilement avec moins de donnÃ©es et moins de temps de calcul Ãªtre affinÃ©s et mis en Å“uvre pour produire des rÃ©sultats qui dÃ©passe the state of the art. Dans ce projet,nous allons montrer comment utiliser BERT avec la bibliothÃ¨que PyTorch pour affiner rapidement et efficacement un modÃ¨le de classification des logs d'Openstack, oÃ¹ notre objectif sera dÃ©tecter les anomalies dans des futurs logs.\n",
        "\n",
        "\n",
        "- **Dataset** - nous allons utiliser une DT open Source d'openstack mais il est sous forme d'un Filelog donc on avait besoin d'utiliser excel(On peut utiliser Python mais excel reste simple) pour insÃ©rer les logs dans des dataframes.\n",
        "\n",
        "- **Objectif** - developper une solution qui permet de detecter les anomalies dans les logs.\n",
        "\n",
        "- **Methodologie** - nous allons considerer comme nous avons un probleme de text classification et construire un deep learning model pour attiendre l'objectif."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-_hnw-Xku3g"
      },
      "source": [
        "#II- Different Models \n",
        "Il existe plusieurs types de modÃ¨les qui pourraient Ãªtre utilisÃ©s pour crÃ©er la solution pour la classification de texte. Quelques exemples sont :\n",
        "\n",
        "\n",
        "*   **1D- Conv Net** : \n",
        "les CNN peuvent Ãªtre utilisÃ©s pour la classification des textes. **Avantage**: ils sont plus rapides Ã  s'entraÃ®ner. En fait, un modÃ¨le CNN pourrait atteindre une prÃ©cision dÃ©cente **Disdvantage**: ils ne parviennent pas Ã  capturer les dÃ©pendances Ã  long terme dans le texte et ne capturent pas les informations sÃ©quentielles dans le texte.\n",
        "\n",
        "*   **ModÃ¨les basÃ©s sur RNN (LSTM, GRU)** : **Avantage**: ils peuvent capturer la nature sÃ©quentielle d'un texte. **InconvÃ©nient** : Plus lent Ã  s'entraÃ®ner.\n",
        "\n",
        "* **ModÃ¨les basÃ©s sur des transformers (BERT, GPT2)** -\n",
        "Les modÃ¨les basÃ©s sur des transformers exploite plusieurs unitÃ©s Transformer et un mÃ©canisme d'attention Ã  multihead. L'avantage est qu'ils se concentrent uniquement sur le mÃ©canisme d'attention. \n",
        "\n",
        "####Dans ce projet nous allons focaliser sur un model basÃ© sur des transformers(encoder partie) qui est le model Bert \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL3D6tBoNmhm"
      },
      "source": [
        "# III- Bert For anomaly detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCrjgooScfD"
      },
      "source": [
        "### 1. Importing libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbgahlBAa6GW",
        "outputId": "a1e027e3-fd12-46d7-8e8e-4bf714ab0a58"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 36.2MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqJIgb2wk4P3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRMWg6qlJsg"
      },
      "source": [
        "###2. Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK_C6jL3Swj9"
      },
      "source": [
        "####**Importing files from Google Drive in Colab**\n",
        "notre dataset est stockÃ©e dans Google Drive donc nous avons besoin de \n",
        "lier notre compte Google Drive avec notre notebook.\n",
        "1. La premiÃ¨re Ã©tape consiste Ã  monter notre Google Drive en exÃ©cutant le code en dessous.\n",
        "2.  nous obtenons le code d'autorisation en nous connectant Ã  notre compte Google.\n",
        "3.   nous collons le code d'autorisation et nous appuyons sur EntrÃ©e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jYBkl_-lCsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b248d9a-f225-4f1e-98a0-70ee5cdab216"
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5Sugn_UlCoX"
      },
      "source": [
        "PATH_normal=r'/gdrive/My Drive/normal.xlsx'\n",
        "PATH_abnormal=r'/gdrive/My Drive/abnormal.xlsx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXOapdOjlCmo"
      },
      "source": [
        "data_normal = pd.read_excel(PATH_normal)\n",
        "data_abnormal = pd.read_excel(PATH_abnormal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwLc-zmNlChA"
      },
      "source": [
        "data_normal.to_csv(r'/gdrive/My Drive/normal1.csv')\n",
        "data_abnormal.to_csv(r'/gdrive/My Drive/abnormal1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q89xkZ2jshSE"
      },
      "source": [
        "df_normal = pd.read_csv(r'/gdrive/My Drive/normal.csv')\n",
        "df_abnormal = pd.read_csv(r'/gdrive/My Drive/abnormal.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQWQPmlisqhi"
      },
      "source": [
        "df_normal=df_normal[['log']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNtbBeRWsrTl"
      },
      "source": [
        "df_abnormal=df_abnormal[['log']]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2VsEYm0lgcI"
      },
      "source": [
        "###3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqI4-0YWs0Aw"
      },
      "source": [
        "* Ajouter les labels (0 normal log, 1 abnormal log)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4kfutPcszJ6"
      },
      "source": [
        "df_normal['label']=0\n",
        "df_abnormal['label']=1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1EdX0Wys_3t"
      },
      "source": [
        "* concatenate and shuffle data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "mOlrJc1ms9tH",
        "outputId": "87c27196-b91e-4464-e705-42c33fd9c8df"
      },
      "source": [
        "#concatinate\n",
        "df=pd.concat([df_normal,df_abnormal])\n",
        "# Shuffle the data\n",
        "df = shuffle(df).reset_index(drop=True)\n",
        "df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>log</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6413</th>\n",
              "      <td>nova-api.log.1.2017-05-17_12:02:19 2017-05-16 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>nova-api.log.2017-05-14_21:27:04 2017-05-14 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6303</th>\n",
              "      <td>nova-api.log.1.2017-05-17_12:02:19 2017-05-16 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5748</th>\n",
              "      <td>nova-api.log.1.2017-05-17_12:02:19 2017-05-16 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6072</th>\n",
              "      <td>nova-api.log.2017-05-14_21:27:04 2017-05-14 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3272</th>\n",
              "      <td>nova-compute.log.1.2017-05-17_12:02:35 2017-05...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7303</th>\n",
              "      <td>nova-api.log.2017-05-14_21:27:04 2017-05-14 20...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8447</th>\n",
              "      <td>nova-api.log.2017-05-14_21:27:04 2017-05-14 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>nova-api.log.2017-05-14_21:27:04 2017-05-14 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3083</th>\n",
              "      <td>nova-compute.log.2017-05-14_21:27:09 2017-05-1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    log  label\n",
              "6413  nova-api.log.1.2017-05-17_12:02:19 2017-05-16 ...      0\n",
              "1265  nova-api.log.2017-05-14_21:27:04 2017-05-14 19...      1\n",
              "6303  nova-api.log.1.2017-05-17_12:02:19 2017-05-16 ...      0\n",
              "5748  nova-api.log.1.2017-05-17_12:02:19 2017-05-16 ...      0\n",
              "6072  nova-api.log.2017-05-14_21:27:04 2017-05-14 19...      1\n",
              "3272  nova-compute.log.1.2017-05-17_12:02:35 2017-05...      0\n",
              "7303  nova-api.log.2017-05-14_21:27:04 2017-05-14 20...      1\n",
              "8447  nova-api.log.2017-05-14_21:27:04 2017-05-14 19...      1\n",
              "259   nova-api.log.2017-05-14_21:27:04 2017-05-14 19...      1\n",
              "3083  nova-compute.log.2017-05-14_21:27:09 2017-05-1...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO6uXniSkch8",
        "outputId": "f73caa5b-44bc-4b1f-9e73-5f2b5a0dc79d"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8923, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhWBm4phZm1l",
        "outputId": "b7ef5921-cc91-4cef-ca89-3f7b951ced57"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8923 entries, 0 to 8922\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   log     8923 non-null   object\n",
            " 1   label   8923 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 139.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HbLvO5HSMVR",
        "outputId": "95392267-5826-4874-e20d-a15930668d50"
      },
      "source": [
        "print('Number of normal log : ', df[\"label\"].value_counts()[0])\n",
        "print('Number of abnormal log : ', df[\"label\"].value_counts()[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of normal log :  5703\n",
            "Number of abnormal log :  3220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp3wlBLbltvM"
      },
      "source": [
        "* Nous supprimons ensuite les caractÃ¨res non alphanumÃ©riques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0oG3RZOlblQ"
      },
      "source": [
        "def clean_data(log):\n",
        "    log = re.sub(\"'\", \"\", log)\n",
        "    log = re.sub(\"(\\\\W)+\", \" \", log)\n",
        "    log = log.lower()\n",
        "    return log\n",
        "\n",
        "df['log'] = df['log'].apply(clean_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94COKNemxbH"
      },
      "source": [
        "* Split the dataset into train(80%, validation 10% and test sets 10%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owGN02hRmtgl"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['log'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# val set & test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVOrNhhKsfMx"
      },
      "source": [
        "###4. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR8otIdCFf0y"
      },
      "source": [
        "* Bert accepte un type spÃ©cifique des inputs pour y rÃ©pondre nous sommes tenus de:\n",
        "1. Ajouter des tokens spÃ©ciaux au dÃ©but[CLS] et Ã  la fin[SEP] de chaque log.\n",
        "2. ComplÃ©ter et tronquer toutes les logs Ã  une seule longueur constante \"padding\".\n",
        "3. DiffÃ©rencier explicitement les vrais tokens des tokens de remplissage avec le \"attention mask\" 1 vrai 0 vide.\n",
        "\n",
        "PS: l'output du dernier transformer(12eme), seul le premier embeddage (correspondant au token [CLS]) est utilisÃ© par le classifieur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYW9hkBya_9j"
      },
      "source": [
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "b36b986ad36c4763a586d9e62f0e2b54",
            "397bc2b375574a18844a61d0645f318d",
            "b2d1c9fa6a2a47c2a6f27c8a1f958ca9",
            "c3632d1eeb344e02b70d71aa7ba338c4",
            "0ef91b8cf88f46e4a0d6d5bf471e8afc",
            "6fc25e699d0c4d988a6a23f90796b52e",
            "9551f66456924532955b0806bd619245",
            "3f196c84166d43259826244dbfd13a0f",
            "7ef29c8a924046e085f59d6ec2a6db64",
            "b0d5591b9cd543bba4555266e9eb5f27",
            "8a06d4d09b544ec8948082a0d6116c55",
            "5dd116408a5442728c10c0da5e7eac58",
            "2c254936732b42c4b2159be5496fadd2",
            "9ad456ac73bc479f9fd4fec3ff0aef94",
            "f6b668e3fd3f44f593104159687fa39c",
            "c4d1016e29f042e5889154e7063d93f9",
            "e06978ad029c4affb3af3b5ca277fec4",
            "6618a4742da14352a955462205b99f3a",
            "9f5d50a521a841c89c8187ba717ab60e",
            "4857291f842f45a8b6d6b69e50fe372a",
            "ad1d8f7875cf41279a68c420da1520c8",
            "424f2c239db04d3283c5dff1df986413",
            "effbc0f2fd6644278e58bfab8b01bba1",
            "978abe723fe045678fa4863de034a856"
          ]
        },
        "id": "z2BNuCUla_60",
        "outputId": "f3761f0e-7003-4072-fd25-b6d9f87193ce"
      },
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b36b986ad36c4763a586d9e62f0e2b54",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ef29c8a924046e085f59d6ec2a6db64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e06978ad029c4affb3af3b5ca277fec4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwGzf09yPTCl"
      },
      "source": [
        "* obtenir une idÃ©e sur la longueur des logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "SSDlyzvra_4b",
        "outputId": "12b5be86-a5a1-453b-95b7-82ba8ddf9b06"
      },
      "source": [
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f95ea6ac210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ski8QBceCHGB"
      },
      "source": [
        "* Mesurer la longueur du plus long log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4_6l5Uha_2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a7d399-9097-4e35-8640-8300a5a4807e"
      },
      "source": [
        "max_len = 0\n",
        "for sent in df.log:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn19WBOFPaCf"
      },
      "source": [
        "* fixer la longueur des logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UI9dwPDBqgu"
      },
      "source": [
        "max_seq_len = 100"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFiNK7OVPhnZ"
      },
      "source": [
        "* Tokenize DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n-UiX8La_xf",
        "outputId": "5304735c-1f5e-41bf-db48-0bd6173ab067"
      },
      "source": [
        "# tokenize & encode sequences training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True, # Pad & truncate all sentences.\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize & encode sequences validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize & encode sequences test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lGABO3Pu9Ke"
      },
      "source": [
        "###5. Convert Data to Tensors(PyTorch Data Types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeamW50KI3P4"
      },
      "source": [
        "Notre modÃ¨le attend des tenseurs PyTorch plutÃ´t que numpy.ndarrays, donc convertissons toutes nos variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMrsp2URa_vD"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikX0DTtkvCzY"
      },
      "source": [
        "###6. Create DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBvfxAzzJcm2"
      },
      "source": [
        "Nous allons Ã©galement crÃ©er un itÃ©rateur pour notre ensemble de donnÃ©es Ã  l'aide de la classe Torch DataLoader. Cela permet d'Ã©conomiser de la mÃ©moire pendant l'entraÃ®nement car, contrairement Ã  une boucle for, avec un itÃ©rateur, l'ensemble de donnÃ©es n'a pas besoin d'Ãªtre chargÃ© en mÃ©moire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Qy66e_a_rY"
      },
      "source": [
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm1aDJvivO1H"
      },
      "source": [
        "###7. Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "59d30097483c4e3a8d8ae2121c5dc53b",
            "bc94a6f3a8e14f919a4a6e3de1db5f15",
            "83e4c01facda4f4982586b89890dc7e2",
            "fac50e5d0acd46fdaaca9694f5095aba",
            "34e79c2ee5e942b083bb67e34b7c0458",
            "ad0f5ccf532a42628080c56f53bdd3f8",
            "0bffd8d85d39481bb28ecd22965d025b",
            "1542e7cfd34041ecbe5c329eb74abcd0",
            "84d0a2b23b664090b6d8892ceba625bf",
            "c9c9c8e7a73748d593f7e6a3e8892bb7",
            "d8f9f9478b224991aed6535280ce8836",
            "7e3083bb14ee49b5a8c1c3f7636e62ac",
            "ab17dec6b0cb4d7aa9ae4db026ced78a",
            "b9d229bd9dd84716b171f06b363b574d",
            "f653c1eac66e4e7ca60b0d5c45a2b681",
            "6612473ac06c46acab270fb56438d7e3"
          ]
        },
        "id": "enMOfkC5IGH8",
        "outputId": "649c0958-4e09-460d-a3ab-55d60ceca96d"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59d30097483c4e3a8d8ae2121c5dc53b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d0a2b23b664090b6d8892ceba625bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90iQTaSSumEx",
        "outputId": "5a718fe7-112e-4171-d053-feef0302b114"
      },
      "source": [
        "bert.cuda()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bg-IKAzvLRG"
      },
      "source": [
        "* Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cfJRDdXa_o_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daYB6uZna_mT"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tiBjLhba_kQ"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model = model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-bMIQ0wLq1S"
      },
      "source": [
        "Maintenant que notre modÃ¨le est chargÃ©, nous devons rÃ©cupÃ©rer les hyperparamÃ¨tres d'entraÃ®nement.\n",
        "- Batch size: 32 (nous en avons choisi 32 lors de la crÃ©ation du DataLoaders).\n",
        "- Learning rate (Adam):nous utiliserons 1e-3.\n",
        "- Nombre d'Ã©poques:nous en utiliserons 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQLPXOc3a_hN"
      },
      "source": [
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr =2e-5)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFdz9GyqvbnM"
      },
      "source": [
        "* Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjy7ucJmfYoe",
        "outputId": "40c6dc9e-e56c-4872-9128-ca696abe5285"
      },
      "source": [
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.78233231 1.38548137]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5nIqgZPQKkz"
      },
      "source": [
        "* convert class weights to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6bfy42Da_eo"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 5"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX9PyY67vn98"
      },
      "source": [
        "###8. Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnqe1JAxa_Y3"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCBRd0ota_WO"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      #elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejb_FBlrv-tt"
      },
      "source": [
        "###9. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFqfA9FPa_S9",
        "outputId": "1bec17a3-867e-4918-f0a4-c7219165326e"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.693\n",
            "Validation Loss: 0.685\n",
            "\n",
            " Epoch 2 / 5\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.688\n",
            "Validation Loss: 0.680\n",
            "\n",
            " Epoch 3 / 5\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.685\n",
            "Validation Loss: 0.676\n",
            "\n",
            " Epoch 4 / 5\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.683\n",
            "Validation Loss: 0.671\n",
            "\n",
            " Epoch 5 / 5\n",
            "  Batch    50  of    224.\n",
            "  Batch   100  of    224.\n",
            "  Batch   150  of    224.\n",
            "  Batch   200  of    224.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.679\n",
            "Validation Loss: 0.668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMHaORKZNMjn"
      },
      "source": [
        "* Jetons un coup d'Å“il au training loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWeusZhuNLKx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RZmRS3MwHFB"
      },
      "source": [
        "###10. Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ldPq5Efa_Qs"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfa3epAga_Nl",
        "outputId": "509e85f8-6baa-4e07-a921-225dbd232af8"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82       571\n",
            "           1       0.68      0.64      0.66       322\n",
            "\n",
            "    accuracy                           0.76       893\n",
            "   macro avg       0.74      0.74      0.74       893\n",
            "weighted avg       0.76      0.76      0.76       893\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHVJJFpTwPIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "058a5b1d-ca93-439e-da24-bfa2b787ffb7"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>476</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>117</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      476   95\n",
              "1      117  205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}