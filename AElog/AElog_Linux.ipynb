{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AElog_Linux.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-_hnw-Xku3g"
      },
      "source": [
        "#I- Introduction\n",
        "Il existe plusieurs types de modèles qui pourraient être utilisés pour la classification de texte. Quelques exemples sont :\n",
        "\n",
        "\n",
        "*   **1D- Conv Net** \n",
        "\n",
        "*   **Modèles basés sur RNN (LSTM, GRU)** \n",
        "\n",
        "* **Modèles basés sur des transformers (BERT, GPT2)** \n",
        "\n",
        "####nous avons testé les 3 types de modèles et les CNN et Bert ont montré des très bonne performance\n",
        "####Dans ce projet nous allons essayer de combiner les deux pour avoir un model plus puissant qui tire parti des atouts de chaque type pour donner des meilleurs résultats.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCrjgooScfD"
      },
      "source": [
        "### 1. Importing libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wkrSDBft4YV_",
        "outputId": "d5e2f349-0dc9-4e24-ec94-d493a7868207"
      },
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install tensorflow-gpu==2.3.0\n",
        "!pip install keras==2.4.3\n",
        "!pip cudatoolkit==11.0.221"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/89/f2d29c2eafc2eeafb17d5634340e06366af904d332341200a49d954bce85/tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.36.2)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow==2.3.0) (57.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.30.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.0.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.4.3)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, numpy, h5py, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/b0/1b3ec22178c021b5ec6c1ace4c3ed20156dabdfcfd998071a7cb9186b1a0/tensorflow_gpu-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 50kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.34.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu==2.3.0) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.30.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.2.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.0\n",
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.15.0)\n",
            "ERROR: unknown command \"cudatoolkit==11.0.221\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up70LU93J0fb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bErBhoUltZS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from numpy import array\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers.core import Activation, Dropout, Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "#from tensorflow.keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ESMlRaKRTw"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRMWg6qlJsg"
      },
      "source": [
        "###2. Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK_C6jL3Swj9"
      },
      "source": [
        "####**Importing files from Google Drive in Colab**\n",
        "notre dataset est stockée dans Google Drive donc nous avons besoin de \n",
        "lier notre compte Google Drive avec notre notebook.\n",
        "1. La première étape consiste à monter notre Google Drive en exécutant le code en dessous.\n",
        "2.  nous obtenons le code d'autorisation en nous connectant à notre compte Google.\n",
        "3.   nous collons le code d'autorisation et nous appuyons sur Entrée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmsF7wREKZOO",
        "outputId": "2bd20bd3-76db-44eb-dabb-d7b791ef0bbf"
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-qhA6JMK9wd"
      },
      "source": [
        "data_access=pd.read_csv(r'/gdrive/My Drive/access.csv')\n",
        "data_maillog=pd.read_csv(r'/gdrive/My Drive/maillog.csv')\n",
        "data_messages=pd.read_csv(r'/gdrive/My Drive/messages.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2VsEYm0lgcI"
      },
      "source": [
        "###3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPPgOMpRK9lN"
      },
      "source": [
        "del data_access['Unnamed: 0']\n",
        "del data_maillog['Unnamed: 0']\n",
        "del data_messages['Unnamed: 0']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "UnZJJUa7K9bY",
        "outputId": "35827951-1011-451a-f8e5-0d10848f898d"
      },
      "source": [
        "#concatinate\n",
        "df=pd.concat([data_access,data_maillog,data_messages])\n",
        "# Shuffle the data\n",
        "df = shuffle(df).reset_index(drop=True)\n",
        "df.sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>log</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5912</th>\n",
              "      <td>Aug 15 07:53:12 combo sendmail[12410]: j7DKe8q...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18443</th>\n",
              "      <td>218.144.240.75 - - [21/Jul/2005:03:37:19 -0400...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2551</th>\n",
              "      <td>Jun 26 16:34:07 combo sendmail[5576]: j5QFs4LO...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11602</th>\n",
              "      <td>Aug 15 18:01:02 combo sendmail[14383]: j7DNgGG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Aug 16 19:13:17 combo sendmail[18127]: j7DIgGx...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9904</th>\n",
              "      <td>Aug 15 05:30:37 combo sendmail[12246]: j7DKcqq...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>Jul  3 23:16:09 combo ftpd[769]: connection fr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9177</th>\n",
              "      <td>210.91.137.35 - - [12/Jun/2005:04:40:08 -0400]...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>Jun 22 13:16:30 combo ftpd[17882]: connection ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5946</th>\n",
              "      <td>Aug 29 02:53:33 combo sendmail[31262]: j7S6GOd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     log  label\n",
              "5912   Aug 15 07:53:12 combo sendmail[12410]: j7DKe8q...      0\n",
              "18443  218.144.240.75 - - [21/Jul/2005:03:37:19 -0400...      0\n",
              "2551   Jun 26 16:34:07 combo sendmail[5576]: j5QFs4LO...      0\n",
              "11602  Aug 15 18:01:02 combo sendmail[14383]: j7DNgGG...      0\n",
              "164    Aug 16 19:13:17 combo sendmail[18127]: j7DIgGx...      0\n",
              "9904   Aug 15 05:30:37 combo sendmail[12246]: j7DKcqq...      0\n",
              "574    Jul  3 23:16:09 combo ftpd[769]: connection fr...      0\n",
              "9177   210.91.137.35 - - [12/Jun/2005:04:40:08 -0400]...      0\n",
              "761    Jun 22 13:16:30 combo ftpd[17882]: connection ...      0\n",
              "5946   Aug 29 02:53:33 combo sendmail[31262]: j7S6GOd...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa5Fqzy4SBNR",
        "outputId": "ad2c412f-ba51-4ceb-ee55-7e1436b7d663"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22278 entries, 0 to 22277\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   log     22278 non-null  object\n",
            " 1   label   22278 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 348.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M20biFiMLOwq"
      },
      "source": [
        "def clean_data(log):\n",
        "    log = re.sub(\"'\", \"\", log)\n",
        "    log = re.sub(\"-\", \"\", log)\n",
        "    log = re.sub(\"_\", \"\", log)\n",
        "    log = re.sub(\"(\\\\W)+\", \" \", log)\n",
        "    log = log.lower()\n",
        "    return log"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMDj-a84L1Qg"
      },
      "source": [
        "df['log'] = df['log'].apply(clean_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94COKNemxbH"
      },
      "source": [
        "* Split the dataset into train set 80% & test sets 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XTMjK1il01g"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['log'],df['label'], test_size=0.2,random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTZUqjFK4pqu"
      },
      "source": [
        "### CNN Processing Part:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs6cPEVJDvFm"
      },
      "source": [
        "#### Preparing the Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6erncuPFx81"
      },
      "source": [
        "nous utiliserons la classe Tokenizer du module keras.preprocessing.text pour créer un dictionnaire de word-to-index . Dans le dictionnaire, chaque mot est utilisé comme clé, tandis qu'un index unique correspondant est utilisé comme valeur pour la clé."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etXzifLgl1ua"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOo_yb2QGP2q"
      },
      "source": [
        "Nous fixons la taille maximale à 150. Les listes de taille supérieure à 150 seront tronquées à 150. Pour les listes dont la longueur est inférieure à 150, nous ajouterons 0 à la fin de la liste jusqu'à ce qu'elle atteigne la longueur maximale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-zUSi5Ll6HV"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 150\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04wvSErOG3FK"
      },
      "source": [
        "Nous utiliserons GloVe embeddings pour créer feature matrix, j'ai essayé d'importer Glove sur mon drive\n",
        "* vous pouvez la trouver sur : https://drive.google.com/file/d/17PIgUPWrXOLFbUYqTAnl1cgWqnWHgX1B/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriS9Fsrl-YA"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "glove_path=r'/gdrive/My Drive/glove.6B.100d.txt'\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open(glove_path, encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxW3vnn6INGC"
      },
      "source": [
        "Enfin, nous allons créer une embedding matrix où chaque numéro de ligne correspondra à l'index du mot. La matrice aura 100 colonnes où chaque colonne contiendra les embeddings de mots GloVe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjvP0cNlmEvK"
      },
      "source": [
        "embedding_matrix = zeros((vocab_size,100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAG-IbUc59uV"
      },
      "source": [
        "### Bert Processing Part:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAsvx_cr8OS9"
      },
      "source": [
        "### Build a BERT Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENRgLwLVKZZj",
        "outputId": "8462b98b-439f-4664-a596-83ddaf951275"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import MaxPooling1D,Conv1D,GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, Input,Concatenate\n",
        "import tensorflow_hub as hub\n",
        "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2, Total size: 421.50MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axwnig5jKz1Z"
      },
      "source": [
        "### **PS: Pour Bert layer:**\n",
        "* Inputs:\n",
        "\n",
        "a) input token ids (tokenizer convertir les tokens à l'aide d'un vocab file)\n",
        "\n",
        "b) input masks (1 pour vrai tokens, 0 pour padding)\n",
        "\n",
        "c) segment ids (for 2 text training: 0 for the first one, 1 for the second one)\n",
        "\n",
        "* Outputs:\n",
        "\n",
        "a) pooled_output: shape [batch_size, 768] avec des représentations pour input sequences\n",
        "\n",
        "b) sequence_output: shape [batch_size, max_len, 768] avec des représentation pour chaque input token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVOrNhhKsfMx"
      },
      "source": [
        "### Bert Tokenization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR8otIdCFf0y"
      },
      "source": [
        "* Bert accepte un type spécifique des inputs pour y répondre nous sommes tenus de:\n",
        "1. Ajouter des tokens spéciaux au début[CLS] et à la fin[SEP] de chaque log.\n",
        "2. Compléter et tronquer toutes les logs à une seule longueur constante \"padding\".\n",
        "3. Différencier explicitement les vrais tokens des tokens de remplissage avec le \"attention mask\" 1 vrai 0 vide.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmGLYThLMuG4",
        "outputId": "d5be461e-d91a-4e2a-ec3b-12f65df7a2e9"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 22.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 22.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 18.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 13.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 10.6MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 11.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 11.2MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 12.0MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 12.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 12.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 12.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 12.0MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 12.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 12.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 12.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 12.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2mObaFwEETF"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "import tokenization"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRBYU10-NvYF"
      },
      "source": [
        "Importons le tokenizer à l'aide du vocab file d'origine, écrivons tous les mots en minuscules, puis tokenisons les logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O7azPH2KZAa"
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "def bert_encode(texts, tokenizer, max_len=150):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNcgvXpSvcSx"
      },
      "source": [
        "X_train0, X_test0, y_train0, y_test0 = train_test_split(df['log'],df['label'], test_size=0.2,random_state=42)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpEeHgqLvTAr"
      },
      "source": [
        "max_len = 150\n",
        "train_input = bert_encode(X_train0, tokenizer, max_len=max_len)\n",
        "test_input = bert_encode(X_test0, tokenizer, max_len=max_len)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylqKV-TlU235"
      },
      "source": [
        " ### **Building the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOj0pvKRWhsv"
      },
      "source": [
        "Avant de voir l'architecture du modèle clarifions quelques choses\n",
        "Prenons un exemple de \"I am fine\".\n",
        "\n",
        "Avant de le transmettre au modèle bert, nous devons ajouter le token [CLS] au début et le token [SEP] à la fin de la phrase.\n",
        "\n",
        "Maintenant, la phrase est \"[CLS] I am fine [SEP]\".\n",
        "\n",
        "Maintenant, si nous donnons la phrase ci-dessus à Bert layer, nous obtiendrons 768 dimension embedding pour chaque token dans le log. Alors, \"sequence output\" donnera une sortie de dimension [1, 5, 768] puisqu'il y a 5 tokens dont [CLS] et [SEP] et \"pooled output\" donnera une sortie de dimension [1, 1, 768] qui est l'embedding de [CLS] token.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXI-ZEX2Qm9m"
      },
      "source": [
        "def AElog():\n",
        "    max_len=150\n",
        "    #Bert layer input a besoin des trois vect (input_word_ids,input_mask,segment_ids)\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    \n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    # Créer un Bert layer\n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    # CLS \n",
        "    cls_output = pooled_output\n",
        "    #CNN Part\n",
        "    ###Building the Model. \n",
        "    input_tensor = Input(shape=(150,))\n",
        "    # Créer un embedding layer(2D)\n",
        "    input_layer= Embedding(vocab_size,100, weights=[embedding_matrix], input_length=maxlen , trainable=False)(input_tensor)\n",
        "    #liste où on va stocker l'output\n",
        "    uni_vec = []\n",
        "    #nous allons utiliser 3 filtres avec des n-grams différents( 2-grams, 3-grams, 4-grams)\n",
        "    filter_sizes = (2,3,4)\n",
        "    for ks in filter_sizes:\n",
        "    #applique 3 convolutions différents à l'embedding layer\n",
        "      conv_layer= Conv1D(128, kernel_size=ks, activation='relu')(input_layer)\n",
        "      maxpool_layer = MaxPooling1D(pool_size=maxlen-ks+1,strides=None, padding='valid')(conv_layer)\n",
        "      flat_layer= Flatten()(maxpool_layer)\n",
        "      uni_vec.append(flat_layer)\n",
        "    # concatiner les outputs de CNN\n",
        "    single_feature_vector = keras.layers.concatenate(uni_vec)\n",
        "    #AElog:\n",
        "    #nous allons concatiner l'output de BERT \"CLS\" et l'output de CNN \"single_feature_vector\"\n",
        "    outp = tf.keras.layers.concatenate([cls_output, single_feature_vector])\n",
        "    #AElog fully Connected Layers\n",
        "    dense = Dense(128, activation='relu')(outp)\n",
        "    dense2 = Dense(128, activation='relu')(dense)\n",
        "    out = Dense(1, activation='sigmoid')(dense2)\n",
        "    #input de CNN input_tensor\n",
        "    input1=input_tensor\n",
        "    #input de Bert layers et input_word_ids, input_mask, segment_ids\n",
        "    input2=[input_word_ids, input_mask, segment_ids]\n",
        "    # donc input du models est les 2\n",
        "    model = Model(inputs=[input1,input2],outputs=out)\n",
        "   #Compile Model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMEWeF39TJlt"
      },
      "source": [
        "model = AElog()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FcmAdGXj9ssj",
        "outputId": "3c904e52-2788-4ad8-a535-69f711440a85"
      },
      "source": [
        "from IPython.display import SVG\n",
        "SVG(tf.keras.utils.model_to_dot(model, show_shapes=True, show_layer_names=True, dpi=65).create(prog='dot', format='svg'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"724pt\" viewBox=\"0.00 0.00 1892.00 802.00\" width=\"1708pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 798)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-798 1888,-798 1888,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140133077943824 -->\n<g class=\"node\" id=\"node1\">\n<title>140133077943824</title>\n<polygon fill=\"none\" points=\"429,-747.5 429,-793.5 691,-793.5 691,-747.5 429,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495.5\" y=\"-766.8\">input_1: InputLayer</text>\n<polyline fill=\"none\" points=\"562,-747.5 562,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"562,-770.5 620,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"620,-747.5 620,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-778.3\">[(?, 150)]</text>\n<polyline fill=\"none\" points=\"620,-770.5 691,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-755.3\">[(?, 150)]</text>\n</g>\n<!-- 140133078417168 -->\n<g class=\"node\" id=\"node2\">\n<title>140133078417168</title>\n<polygon fill=\"none\" points=\"407,-664.5 407,-710.5 713,-710.5 713,-664.5 407,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-683.8\">embedding: Embedding</text>\n<polyline fill=\"none\" points=\"563,-664.5 563,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"563,-687.5 621,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"621,-664.5 621,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667\" y=\"-695.3\">(?, 150)</text>\n<polyline fill=\"none\" points=\"621,-687.5 713,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"667\" y=\"-672.3\">(?, 150, 100)</text>\n</g>\n<!-- 140133077943824&#45;&gt;140133078417168 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140133077943824-&gt;140133078417168</title>\n<path d=\"M560,-747.3799C560,-739.1745 560,-729.7679 560,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"563.5001,-720.784 560,-710.784 556.5001,-720.784 563.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140133078408464 -->\n<g class=\"node\" id=\"node3\">\n<title>140133078408464</title>\n<polygon fill=\"none\" points=\"88,-581.5 88,-627.5 356,-627.5 356,-581.5 88,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-600.8\">conv1d: Conv1D</text>\n<polyline fill=\"none\" points=\"206,-581.5 206,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"206,-604.5 264,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"264,-581.5 264,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-612.3\">(?, 150, 100)</text>\n<polyline fill=\"none\" points=\"264,-604.5 356,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-589.3\">(?, 149, 128)</text>\n</g>\n<!-- 140133078417168&#45;&gt;140133078408464 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140133078417168-&gt;140133078408464</title>\n<path d=\"M466.297,-664.4901C422.6135,-653.7631 370.4933,-640.9643 325.636,-629.9491\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.4314,-626.5405 315.8853,-627.5547 324.7621,-633.3385 326.4314,-626.5405\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502706896 -->\n<g class=\"node\" id=\"node4\">\n<title>140131502706896</title>\n<polygon fill=\"none\" points=\"418.5,-581.5 418.5,-627.5 701.5,-627.5 701.5,-581.5 418.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-600.8\">conv1d_1: Conv1D</text>\n<polyline fill=\"none\" points=\"551.5,-581.5 551.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"551.5,-604.5 609.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"580.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"609.5,-581.5 609.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-612.3\">(?, 150, 100)</text>\n<polyline fill=\"none\" points=\"609.5,-604.5 701.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-589.3\">(?, 148, 128)</text>\n</g>\n<!-- 140133078417168&#45;&gt;140131502706896 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140133078417168-&gt;140131502706896</title>\n<path d=\"M560,-664.3799C560,-656.1745 560,-646.7679 560,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"563.5001,-637.784 560,-627.784 556.5001,-637.784 563.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502729680 -->\n<g class=\"node\" id=\"node5\">\n<title>140131502729680</title>\n<polygon fill=\"none\" points=\"763.5,-581.5 763.5,-627.5 1046.5,-627.5 1046.5,-581.5 763.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"830\" y=\"-600.8\">conv1d_2: Conv1D</text>\n<polyline fill=\"none\" points=\"896.5,-581.5 896.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"925.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"896.5,-604.5 954.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"925.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"954.5,-581.5 954.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1000.5\" y=\"-612.3\">(?, 150, 100)</text>\n<polyline fill=\"none\" points=\"954.5,-604.5 1046.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1000.5\" y=\"-589.3\">(?, 147, 128)</text>\n</g>\n<!-- 140133078417168&#45;&gt;140131502729680 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140133078417168-&gt;140131502729680</title>\n<path d=\"M655.6436,-664.4901C700.2317,-653.7631 753.4314,-640.9643 799.2177,-629.9491\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"800.2665,-633.2967 809.1704,-627.5547 798.6291,-626.4909 800.2665,-633.2967\" stroke=\"#000000\"/>\n</g>\n<!-- 140133084230544 -->\n<g class=\"node\" id=\"node6\">\n<title>140133084230544</title>\n<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 356,-544.5 356,-498.5 0,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-517.8\">max_pooling1d: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"206,-498.5 206,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"206,-521.5 264,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"264,-498.5 264,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-529.3\">(?, 149, 128)</text>\n<polyline fill=\"none\" points=\"264,-521.5 356,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-506.3\">(?, 1, 128)</text>\n</g>\n<!-- 140133078408464&#45;&gt;140133084230544 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140133078408464-&gt;140133084230544</title>\n<path d=\"M209.7435,-581.3799C205.2046,-572.8178 199.9723,-562.9477 195.0817,-553.7222\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"198.1195,-551.98 190.3433,-544.784 191.9348,-555.2586 198.1195,-551.98\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502478480 -->\n<g class=\"node\" id=\"node7\">\n<title>140131502478480</title>\n<polygon fill=\"none\" points=\"374.5,-498.5 374.5,-544.5 745.5,-544.5 745.5,-498.5 374.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-517.8\">max_pooling1d_1: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"595.5,-498.5 595.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"595.5,-521.5 653.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"653.5,-498.5 653.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699.5\" y=\"-529.3\">(?, 148, 128)</text>\n<polyline fill=\"none\" points=\"653.5,-521.5 745.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699.5\" y=\"-506.3\">(?, 1, 128)</text>\n</g>\n<!-- 140131502706896&#45;&gt;140131502478480 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140131502706896-&gt;140131502478480</title>\n<path d=\"M560,-581.3799C560,-573.1745 560,-563.7679 560,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"563.5001,-554.784 560,-544.784 556.5001,-554.784 563.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140133076183696 -->\n<g class=\"node\" id=\"node8\">\n<title>140133076183696</title>\n<polygon fill=\"none\" points=\"763.5,-498.5 763.5,-544.5 1134.5,-544.5 1134.5,-498.5 763.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"874\" y=\"-517.8\">max_pooling1d_2: MaxPooling1D</text>\n<polyline fill=\"none\" points=\"984.5,-498.5 984.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"984.5,-521.5 1042.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1013.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"1042.5,-498.5 1042.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1088.5\" y=\"-529.3\">(?, 147, 128)</text>\n<polyline fill=\"none\" points=\"1042.5,-521.5 1134.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1088.5\" y=\"-506.3\">(?, 1, 128)</text>\n</g>\n<!-- 140131502729680&#45;&gt;140133076183696 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140131502729680-&gt;140133076183696</title>\n<path d=\"M917.2565,-581.3799C921.7954,-572.8178 927.0277,-562.9477 931.9183,-553.7222\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"935.0652,-555.2586 936.6567,-544.784 928.8805,-551.98 935.0652,-555.2586\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502568464 -->\n<g class=\"node\" id=\"node12\">\n<title>140131502568464</title>\n<polygon fill=\"none\" points=\"123.5,-415.5 123.5,-461.5 356.5,-461.5 356.5,-415.5 123.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-434.8\">flatten: Flatten</text>\n<polyline fill=\"none\" points=\"221.5,-415.5 221.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"221.5,-438.5 279.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"279.5,-415.5 279.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318\" y=\"-446.3\">(?, 1, 128)</text>\n<polyline fill=\"none\" points=\"279.5,-438.5 356.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"318\" y=\"-423.3\">(?, 128)</text>\n</g>\n<!-- 140133084230544&#45;&gt;140131502568464 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140133084230544-&gt;140131502568464</title>\n<path d=\"M195.2705,-498.3799C201.8661,-489.5502 209.5009,-479.3295 216.575,-469.8593\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"219.4266,-471.8902 222.6071,-461.784 213.8185,-467.701 219.4266,-471.8902\" stroke=\"#000000\"/>\n</g>\n<!-- 140133079338640 -->\n<g class=\"node\" id=\"node13\">\n<title>140133079338640</title>\n<polygon fill=\"none\" points=\"436,-415.5 436,-461.5 684,-461.5 684,-415.5 436,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-434.8\">flatten_1: Flatten</text>\n<polyline fill=\"none\" points=\"549,-415.5 549,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"578\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"549,-438.5 607,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"578\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"607,-415.5 607,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"645.5\" y=\"-446.3\">(?, 1, 128)</text>\n<polyline fill=\"none\" points=\"607,-438.5 684,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"645.5\" y=\"-423.3\">(?, 128)</text>\n</g>\n<!-- 140131502478480&#45;&gt;140133079338640 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140131502478480-&gt;140133079338640</title>\n<path d=\"M560,-498.3799C560,-490.1745 560,-480.7679 560,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"563.5001,-471.784 560,-461.784 556.5001,-471.784 563.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140133078090384 -->\n<g class=\"node\" id=\"node14\">\n<title>140133078090384</title>\n<polygon fill=\"none\" points=\"702,-415.5 702,-461.5 950,-461.5 950,-415.5 702,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"758.5\" y=\"-434.8\">flatten_2: Flatten</text>\n<polyline fill=\"none\" points=\"815,-415.5 815,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"815,-438.5 873,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"873,-415.5 873,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"911.5\" y=\"-446.3\">(?, 1, 128)</text>\n<polyline fill=\"none\" points=\"873,-438.5 950,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"911.5\" y=\"-423.3\">(?, 128)</text>\n</g>\n<!-- 140133076183696&#45;&gt;140133078090384 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140133076183696-&gt;140133078090384</title>\n<path d=\"M914.7376,-498.3799C900.5954,-488.8367 884.045,-477.6686 869.0934,-467.5793\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"870.7523,-464.4764 860.5052,-461.784 866.8367,-470.2789 870.7523,-464.4764\" stroke=\"#000000\"/>\n</g>\n<!-- 140133077943568 -->\n<g class=\"node\" id=\"node9\">\n<title>140133077943568</title>\n<polygon fill=\"none\" points=\"968,-415.5 968,-461.5 1276,-461.5 1276,-415.5 968,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1057.5\" y=\"-434.8\">input_word_ids: InputLayer</text>\n<polyline fill=\"none\" points=\"1147,-415.5 1147,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1176\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"1147,-438.5 1205,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1176\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"1205,-415.5 1205,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240.5\" y=\"-446.3\">[(?, 150)]</text>\n<polyline fill=\"none\" points=\"1205,-438.5 1276,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1240.5\" y=\"-423.3\">[(?, 150)]</text>\n</g>\n<!-- 140133017892368 -->\n<g class=\"node\" id=\"node15\">\n<title>140133017892368</title>\n<polygon fill=\"none\" points=\"1022,-332.5 1022,-378.5 1410,-378.5 1410,-332.5 1022,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1099\" y=\"-351.8\">keras_layer: KerasLayer</text>\n<polyline fill=\"none\" points=\"1176,-332.5 1176,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1205\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"1176,-355.5 1234,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1205\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"1234,-332.5 1234,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1322\" y=\"-363.3\">[(?, 150), (?, 150), (?, 150)]</text>\n<polyline fill=\"none\" points=\"1234,-355.5 1410,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1322\" y=\"-340.3\">[(?, 768), (?, 150, 768)]</text>\n</g>\n<!-- 140133077943568&#45;&gt;140133017892368 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140133077943568-&gt;140133017892368</title>\n<path d=\"M1148.1842,-415.3799C1158.6891,-406.1043 1170.9326,-395.2936 1182.1029,-385.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1184.4507,-388.0265 1189.6302,-378.784 1179.8175,-382.7793 1184.4507,-388.0265\" stroke=\"#000000\"/>\n</g>\n<!-- 140134136550160 -->\n<g class=\"node\" id=\"node10\">\n<title>140134136550160</title>\n<polygon fill=\"none\" points=\"1294,-415.5 1294,-461.5 1578,-461.5 1578,-415.5 1294,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1371.5\" y=\"-434.8\">input_mask: InputLayer</text>\n<polyline fill=\"none\" points=\"1449,-415.5 1449,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1478\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"1449,-438.5 1507,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1478\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"1507,-415.5 1507,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1542.5\" y=\"-446.3\">[(?, 150)]</text>\n<polyline fill=\"none\" points=\"1507,-438.5 1578,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1542.5\" y=\"-423.3\">[(?, 150)]</text>\n</g>\n<!-- 140134136550160&#45;&gt;140133017892368 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140134136550160-&gt;140133017892368</title>\n<path d=\"M1375.0099,-415.4901C1347.5902,-405.1454 1315.0635,-392.874 1286.5946,-382.1334\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1287.7005,-378.8099 1277.1088,-378.5547 1285.2296,-385.3593 1287.7005,-378.8099\" stroke=\"#000000\"/>\n</g>\n<!-- 140131499714512 -->\n<g class=\"node\" id=\"node11\">\n<title>140131499714512</title>\n<polygon fill=\"none\" points=\"1596,-415.5 1596,-461.5 1884,-461.5 1884,-415.5 1596,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1675.5\" y=\"-434.8\">segment_ids: InputLayer</text>\n<polyline fill=\"none\" points=\"1755,-415.5 1755,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1784\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"1755,-438.5 1813,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1784\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"1813,-415.5 1813,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1848.5\" y=\"-446.3\">[(?, 150)]</text>\n<polyline fill=\"none\" points=\"1813,-438.5 1884,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1848.5\" y=\"-423.3\">[(?, 150)]</text>\n</g>\n<!-- 140131499714512&#45;&gt;140133017892368 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140131499714512-&gt;140133017892368</title>\n<path d=\"M1595.7747,-415.6552C1526.187,-404.6327 1442.6017,-391.393 1371.5836,-380.144\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1372.0733,-376.678 1361.6488,-378.5703 1370.9781,-383.5918 1372.0733,-376.678\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502623440 -->\n<g class=\"node\" id=\"node16\">\n<title>140131502623440</title>\n<polygon fill=\"none\" points=\"534,-332.5 534,-378.5 928,-378.5 928,-332.5 534,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"614\" y=\"-351.8\">concatenate: Concatenate</text>\n<polyline fill=\"none\" points=\"694,-332.5 694,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"694,-355.5 752,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"723\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"752,-332.5 752,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"840\" y=\"-363.3\">[(?, 128), (?, 128), (?, 128)]</text>\n<polyline fill=\"none\" points=\"752,-355.5 928,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"840\" y=\"-340.3\">(?, 384)</text>\n</g>\n<!-- 140131502568464&#45;&gt;140131502623440 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140131502568464-&gt;140131502623440</title>\n<path d=\"M356.6714,-418.7775C424.9322,-407.2386 511.7337,-392.5654 584.561,-380.2544\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"585.4644,-383.6515 594.7412,-378.5336 584.2976,-376.7494 585.4644,-383.6515\" stroke=\"#000000\"/>\n</g>\n<!-- 140133079338640&#45;&gt;140131502623440 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140133079338640-&gt;140131502623440</title>\n<path d=\"M607.633,-415.3799C628.2994,-405.3488 652.6648,-393.5224 674.2597,-383.0406\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"675.8582,-386.1553 683.3261,-378.6399 672.8015,-379.8579 675.8582,-386.1553\" stroke=\"#000000\"/>\n</g>\n<!-- 140133078090384&#45;&gt;140131502623440 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140133078090384-&gt;140131502623440</title>\n<path d=\"M799.5372,-415.3799C788.9206,-406.1043 776.5468,-395.2936 765.2577,-385.4304\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"767.4839,-382.7277 757.6504,-378.784 762.8783,-387.9992 767.4839,-382.7277\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502703120 -->\n<g class=\"node\" id=\"node17\">\n<title>140131502703120</title>\n<polygon fill=\"none\" points=\"757,-249.5 757,-295.5 1113,-295.5 1113,-249.5 757,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844.5\" y=\"-268.8\">concatenate_1: Concatenate</text>\n<polyline fill=\"none\" points=\"932,-249.5 932,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"932,-272.5 990,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"990,-249.5 990,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051.5\" y=\"-280.3\">[(?, 768), (?, 384)]</text>\n<polyline fill=\"none\" points=\"990,-272.5 1113,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051.5\" y=\"-257.3\">(?, 1152)</text>\n</g>\n<!-- 140133017892368&#45;&gt;140131502703120 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140133017892368-&gt;140131502703120</title>\n<path d=\"M1138.099,-332.4901C1102.3152,-321.9205 1059.7218,-309.3395 1022.8046,-298.4352\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1023.6344,-295.0308 1013.0525,-295.5547 1021.6514,-301.7441 1023.6344,-295.0308\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502623440&#45;&gt;140131502703120 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140131502623440-&gt;140131502703120</title>\n<path d=\"M787.5545,-332.4901C812.7589,-322.2353 842.6169,-310.0872 868.85,-299.414\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"870.3919,-302.5653 878.3355,-295.5547 867.7538,-296.0814 870.3919,-302.5653\" stroke=\"#000000\"/>\n</g>\n<!-- 140131502708304 -->\n<g class=\"node\" id=\"node18\">\n<title>140131502708304</title>\n<polygon fill=\"none\" points=\"826,-166.5 826,-212.5 1044,-212.5 1044,-166.5 826,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-185.8\">dense: Dense</text>\n<polyline fill=\"none\" points=\"918,-166.5 918,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"918,-189.5 976,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"947\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"976,-166.5 976,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-197.3\">(?, 1152)</text>\n<polyline fill=\"none\" points=\"976,-189.5 1044,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1010\" y=\"-174.3\">(?, 128)</text>\n</g>\n<!-- 140131502703120&#45;&gt;140131502708304 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140131502703120-&gt;140131502708304</title>\n<path d=\"M935,-249.3799C935,-241.1745 935,-231.7679 935,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"938.5001,-222.784 935,-212.784 931.5001,-222.784 938.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140133077869584 -->\n<g class=\"node\" id=\"node19\">\n<title>140133077869584</title>\n<polygon fill=\"none\" points=\"821.5,-83.5 821.5,-129.5 1048.5,-129.5 1048.5,-83.5 821.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"875\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"928.5,-83.5 928.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"928.5,-106.5 986.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"986.5,-83.5 986.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1017.5\" y=\"-114.3\">(?, 128)</text>\n<polyline fill=\"none\" points=\"986.5,-106.5 1048.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1017.5\" y=\"-91.3\">(?, 128)</text>\n</g>\n<!-- 140131502708304&#45;&gt;140133077869584 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140131502708304-&gt;140133077869584</title>\n<path d=\"M935,-166.3799C935,-158.1745 935,-148.7679 935,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"938.5001,-139.784 935,-129.784 931.5001,-139.784 938.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140133078733392 -->\n<g class=\"node\" id=\"node20\">\n<title>140133078733392</title>\n<polygon fill=\"none\" points=\"821.5,-.5 821.5,-46.5 1048.5,-46.5 1048.5,-.5 821.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"875\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"928.5,-.5 928.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"928.5,-23.5 986.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"957.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"986.5,-.5 986.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1017.5\" y=\"-31.3\">(?, 128)</text>\n<polyline fill=\"none\" points=\"986.5,-23.5 1048.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1017.5\" y=\"-8.3\">(?, 1)</text>\n</g>\n<!-- 140133077869584&#45;&gt;140133078733392 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140133077869584-&gt;140133078733392</title>\n<path d=\"M935,-83.3799C935,-75.1745 935,-65.7679 935,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"938.5001,-56.784 935,-46.784 931.5001,-56.784 938.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkzl9o2rOl9d",
        "outputId": "29be734b-c6e4-4f31-b48f-6eaf36554932"
      },
      "source": [
        "history = model.fit([X_train,train_input],y_train0,validation_split=0.2,epochs=3,batch_size=16)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "892/892 [==============================] - 964s 1s/step - loss: 0.0219 - acc: 0.9935 - val_loss: 0.0012 - val_acc: 0.9997\n",
            "Epoch 2/3\n",
            "892/892 [==============================] - 958s 1s/step - loss: 0.0017 - acc: 0.9996 - val_loss: 1.5390e-04 - val_acc: 1.0000\n",
            "Epoch 3/3\n",
            "892/892 [==============================] - 956s 1s/step - loss: 6.9753e-05 - acc: 1.0000 - val_loss: 7.3685e-07 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7YmpY7j4BO0",
        "outputId": "87f599e6-a2ba-48ec-c5e7-b127c9a40c58"
      },
      "source": [
        "score = model.evaluate([X_test,test_input], y_test0, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140/140 [==============================] - 86s 616ms/step - loss: 1.4454e-06 - acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}